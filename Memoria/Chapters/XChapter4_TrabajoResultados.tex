\Chapter{Trabajo y Resultados}{Implementación, Optimización, Experimentos y Resultados}

\section{Implementación}
\index{Implementación A*}

Tanto \Python como C++ son lenguajes orientados a objetos.
Esta sección contiene las descripciones de las diferentes
clases diseñadas para dar soporte al algoritmo.

\begin{notebox}
El principal contenido de esta investigación es el estudio
de distintas implementaciones paralelas del algoritmo A*,
por ello es necesario tener alguna noción sobre la Implementación
del algoritmo.
\end{notebox}

\subsection{Task}
\index{Implementación A*!Task}

La clase \lstinline{Task} correspone a una tarea a realizar.
Una instancia de esta clase está definida por los atributos:
\begin{itemize}[itemsep=0.25px]
    \item \lstinline{unsigned int duration}: Duración de la tarea.
    \item \lstinline{std::vector<int> qualified_workers}: Listado de trabajadores que pueden realizar la tarea.
\end{itemize}

\subsection{State}
\index{Implementación A*!State}

La clase \lstinline{State} corresponde a un estado (o nodo).
Una instancia de esta clase está definida por los atributos:
\begin{itemize}[itemsep=0.25px]
    \item \lstinline{std::vector<std::vector<Task>> jobs}: Lista de trabajos y tareas a ejecutar.
    \item \lstinline{std::vector<std::vector<int>> schedule}: Planificación actual.
    \item \lstinline{std::vector<int> workers_status}: Instantes en los que cada trabajador queda libre.
\end{itemize}

\begin{notebox}
    Nótese que el atributo \lstinline{std::vector<std::vector<Task>> jobs} será el mismo
    en todos los estados de un mismo problema.
    Por lo que no será necesario revisarlo en
    \lstinline{State::operator==} ni \lstinline{State::operator()}.
    Si el consumo de memoria fuese de importancia,
    sería posible utilizar una referencia para evitar
    almacenar esta estructura múltiples veces.
\end{notebox}

El algoritmo A* requiere que se creen estructuras de datos que contendrán instancias
de la clase \lstinline{State}.
Estas estructuras necesitan que se proporcionen implementaciones para los operadores
\lstinline{State::operator==} y \lstinline{State::operator()} de la clase \lstinline{State}.
Para diseñar las implementaciones de estos operadores
se estudian previamente los atributos que componen la clase \lstinline{State}:

\begin{itemize}[itemsep=0.25px]
    \item \lstinline{std::vector<std::vector<Task>> jobs}: Es igual en todas las
    instancias de \lstinline{State}, por lo que será ignorado.
    \item \lstinline{std::vector<std::vector<int>> schedule}: Proporciona
    información crucial sobre el estado ($cost_g$ y $cost_h$).
    \item \lstinline{std::vector<int> workers_status}: No proporciona
    información alguna sobre los costes,
    pero es necesario para distinguir dos estados diferentes
    ya que es posible que dos estados tengan los mismos costes pero a través de
    planificaciones distintas.
\end{itemize}

Por ello, será necesario definir dos operadores \lstinline{State::operator()}:
uno que sea indiferente al atributo \lstinline{std::vector<int> workers_status}
(\lstinline{StateHash::operator()})
y otro que sí lo tenga en cuenta para distinguir diferentes instancias de \lstinline{State}
(\lstinline{FullHash::operator()}).

\pagebreak
\section{Optimización}
\index{Optimización A*}

\subsection{Algoritmo A* monohilo}
\index{Optimización A*!Monohilo}

La siguiente subsección estudia la optimización
del algoritmo A* sin tener en cuenta el paralelismo,
esto es, se trata de optimizar el rendimiento
monohilo del mismo.

\subsubsection{State}
\index{Optimización A*!Monohilo!State}

La operación \lstinline{operator()} es ejecutada varias veces para cada
\lstinline{State}, este método tiene una complejidad de $O(n^2)$,
por lo que su valor se almacena tras calcularlo por primera vez
en un atributo del propio \lstinline{State}.

Los operadores \lstinline{operator==} necesarios se implementan utilizando
los \lstinline{operator()} correspondientes.
Las funciones hash utilizadas en los \lstinline{operator()}
son resistentes a colisiones,
esto es, $
h(State_a) \ne h(State_b) \iff State_a \ne State_b
$
por lo que se pueden
utilizar para comparar elementos en \lstinline{operator==}.

\pagebreak
\subsubsection{Coste H - Heurístico}
\index{Optimización A*!Monohilo!Heurísticos}
\label{ssec:Heuristicos}

La principal decisión que afectará al tiempo de ejecución
del algoritmo se encuentra en la Implementación
de la función heurística encargada de calcular el coste H.
Este coste se utiliza para seleccionar el siguiente nodo
a expandir, por lo que un buen heurístico es aquel que
mejor dirige al algoritmo en la dirección del nodo objetivo.

El rendimiento y calidad del resultado del algoritmo
dependerán en gran medida de la función seleccionada.
En algunos casos la implementación retornará resultados
óptimos (o cercanos al óptimo) pero requerirá un mayor tiempo
de ejecución, mientras que otras implementaciones
requerirán un menor tiempo de ejecución pero sus resultados
no serán óptimos.
Dependiendo del problema a resolver será conveniente implementar
una función heurística de un tipo u otro.

\begin{keynotebox}
    Las funciones heurísticas son una estimación del
    tiempo restante hasta completar todas las tareas.
    Esta estimación puede ser una cota inferior o superior.
    Las cotas inferiores retornarán soluciones óptimas a costa de explorar más nodos.
    Las cotas superiores retornarán soluciones de peor calidad a coste de explorar menos nodos.
\end{keynotebox}

\paragraph{Heurístico para optimalidad}~
\index{Optimización A*!Monohilo!Heurísticos!Resultado Óptimo}

La siguiente implementación de la función heurística
dirigirá al algoritmo hacia nodos solución que sean óptimos
o se encuentren relativamente cerca del óptimo.
$$
    cost_h = max_{0 \leq j \le J}\left(
        \sum_{t=k}^{T}{D_{j,t}}
    \right)
$$
\begin{examplebox}
    El conjunto de datos:
    \begin{enumerate}[itemsep=0.25px]
        \item (2, 0), (4, 1), (5, 2)
        \item (5, 3), (2, 4), (1, 5)
    \end{enumerate}
    La planificación:
    \begin{enumerate}[itemsep=0.25px]
        \item (0, 2, -1)
        \item (0, -1, -1)
    \end{enumerate}
    Se calcula la suma de la duración de las tareas no planificadas de cada trabajo:
    \begin{enumerate}[itemsep=0.25px]
        \item (0, 2, -1): 5
        \item (0, -1, -1): 3
    \end{enumerate}
    Se obtiene el máximo: $cost_h = max(5, 3) = 5$
\end{examplebox}

\pagebreak

\paragraph{Heurístico para tiempo}~
\index{Optimización A*!Monohilo!Heurísticos!Rápido}

La siguiente implementación de la función heurística
dirigirá al algoritmo hacia cualquier nodo solución
independientemente de si es óptimo o no.
$$
    cost_h = \sum_{j=0}^{J}{\sum_{t=k}^{T}{D_{j,t}}}
$$
La función calcula el tiempo necesario para completar
las tareas restantes si se ejecutasen una a una
y retorna esta suma.

\begin{examplebox}
    El conjunto de datos:
    \begin{enumerate}[itemsep=0.25px]
        \item (2, 0), (4, 1), (5, 2)
        \item (5, 3), (2, 4), (1, 5)
    \end{enumerate}
    La planificación:
    \begin{enumerate}[itemsep=0.25px]
        \item (0, 2, -1)
        \item (0, -1, -1)
    \end{enumerate}

    Se suman todas las duraciones de las tareas no planificadas:
    $$
    cost_h = \sum_{j=0}^{J}{
        \sum_{t=k}^{T}{
            D_{j,t}
        }
    }
    = 5 + 2 + 1 = 8
    $$ 
\end{examplebox}

\begin{notebox}
    A pesar de que ambas implementaciones tienen la misma complejidad ($O(n^2)$),
    un algoritmo A* utilizando de ellas tardará varias magnitudes de tiempo más que
    si utilizase la otra aunque retornará resultados notablemente mejores en algunos casos.
\end{notebox}

\pagebreak

\subsection{Paralelización}
\index{Optimización A*!Multihilo}

En la siguiente subsección
se estudia la paralelización
del algoritmo A*.
Este estudio está compuesto por la descripción y
comparación de distintas alternativas discutidas en
la literatura.

El algoritmo A* monohilo retorna la solución óptima
para el problema.
Esta característica no se mantiene para todas las
implementaciones paralelas.
Esto sucederá cuando no exista sincronización
entre los distintos hilos,
o lo que es lo mismo,
cuando existan condiciones de carrera
que puedan alterar el curso del algoritmo.

\begin{examplebox}
    Una estrategia en la que los hilos procesen nodos
    a medida que se insertan en el \lstinline{open_set}
    tendrá condiciones de carrera.
    La solución dependerá de qué hilo procese qué estado
    primero.
\end{examplebox}


\subsubsection{First Come First Serve (FCFS) Solver}
\index{Optimización A*!Multihilo!First Come First Serve (FCFS) Solver}

Sería posible desarrollar una implementación que paralelice el procesamiento de los nodos,
asignando uno a cada hilo de forma que para $N$ hilos se procesen $N$ nodos
de forma simultánea (Véase Figura \ref{fig:RepresentacionFCFS}).
\begin{keynotebox}
La estrategia FCFS permite que los hilos procesen los nodos a medida que entran en 
el \lstinline{open_set} .
\end{keynotebox}

\begin{figure}[h]
    \begin{center}
        \begin{tikzpicture}[node distance=2cm]
            \node (00) [process] {\lstinline{open_set}};
            \node (01) [process, right of=00, xshift=6cm] {Procesa nodo};

            \draw [arrow] (00) to [bend left] node [anchor=south] {Extrae nodo} (01);
            \draw [arrow] (01) to [bend left] node [anchor=north] {Inserta vecinos} (00);
        \end{tikzpicture}
    \end{center}
    \caption{Representación de la estrategia FCFS}
    \label{fig:RepresentacionFCFS}
\end{figure}

De cualquier forma, este diseño en particular no tiene por qué reducir el tiempo
requerido para hallar un nodo solución, simplemente tiene la oportunidad de reducirlo
en algunos casos específicos.
Esto se debe a que la única diferencia entre las versiones monohilo y multihilo
es que en la multihilo se procesan más nodos en el mismo tiempo.
(Véase Figura \ref{fig:A*Comparison})

\begin{figure}[h]
\begin{subfigure}{.5\textwidth}
\begin{center}
\begin{tikzpicture}[node distance=1.5cm]
    \node (00) [dot, fill=green!30] {00};
    \node (01) [dot, right of=00] {01};
    \node (02) [dot, right of=01] {02};
    \node (03) [dot, right of=02] {03};

    \node (10) [dot, below of=00] {10};
    \node (11) [dot, right of=10, fill=blue!30] {11};
    \node (12) [dot, right of=11] {12};
    \node (13) [dot, right of=12] {13};

    \node (20) [dot, below of=10] {20};
    \node (21) [dot, right of=20] {21};
    \node (22) [dot, right of=21, fill=blue!30] {22};
    \node (23) [dot, right of=22] {23};

    \node (30) [dot, below of=20] {30};
    \node (31) [dot, right of=30] {31};
    \node (32) [dot, right of=31] {32};
    \node (33) [dot, right of=32, fill=yellow!30] {33};

    \draw [arrow] (00) -- (11);
    \draw [arrow] (11) -- (22);
    \draw [arrow] (22) -- (33);
\end{tikzpicture}
\subcaption{Algoritmo A* monohilo}
\end{center}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\begin{center}
\begin{tikzpicture}[node distance=1.5cm]
    \node (00) [dot, fill=green!30] {00};
    \node (01) [dot, right of=00, fill=blue!30] {01};
    \node (02) [dot, right of=01] {02};
    \node (03) [dot, right of=02] {03};

    \node (10) [dot, below of=00, fill=blue!30] {10};
    \node (11) [dot, right of=10, fill=blue!30] {11};
    \node (12) [dot, right of=11, fill=blue!30] {12};
    \node (13) [dot, right of=12] {13};

    \node (20) [dot, below of=10] {20};
    \node (21) [dot, right of=20, fill=blue!30] {21};
    \node (22) [dot, right of=21, fill=blue!30] {22};
    \node (23) [dot, right of=22, fill=blue!30] {23};

    \node (30) [dot, below of=20] {30};
    \node (31) [dot, right of=30] {31};
    \node (32) [dot, right of=31, fill=blue!30] {32};
    \node (33) [dot, right of=32, fill=yellow!30] {33};

    \draw [arrow] (00) -- (11);
    \draw [arrow] (00) -- (01);
    \draw [arrow] (00) -- (10);
    \draw [arrow] (11) -- (22);
    \draw [arrow] (11) -- (12);
    \draw [arrow] (11) -- (21);
    \draw [arrow] (22) -- (33);
    \draw [arrow] (22) -- (23);
    \draw [arrow] (22) -- (32);
\end{tikzpicture}
\subcaption{Algoritmo A* multihilo (3 hilos)}
\end{center}
\end{subfigure}
\caption{Comparativa entre algoritmos monohilo y multihilo}
\label{fig:A*Comparison}
\end{figure}

\begin{notebox}
    Nótese que este acercamiento no tiene sincronización entre diferentes iteraciones,
    esto implica que la solución está sujeta a una condición de carrera
    (i.e. la solución depende de qué hilo finalice primero su ejecución).
    Por lo que sería posible ejecutar $N$ veces este algoritmo y obtener
    $N$ soluciones diferentes.
\end{notebox}

\paragraph{Secciones críticas}~

El diseño paralelo propuesto no es sin inconvenientes,
su implementación contiene varias secciones críticas que suponen
una amenaza para el rendimiento del algoritmo.
A continuación se observan cada una de estas secciones y se
analizan las razones por las cuales son necesarias.

\subparagraph{Variables de control de flujo}~

Primero, al paralelizar el algoritmo siguiendo esta estrategia,
se han añadido variables de control compartidas por todos
los hilos que sirven para conocer si se ha resuelto el problema
o no (una variable donde se copia el resultado y
otra que sirve como \italic{flag}).
El acceso a estas variables debe estar controlado
para evitar el acceso simultaneo a las mismas.
De cualquier forma, es improbable que dos hilos tengan
la necesidad de acceder esta sección crítica ya que sólo
se ejecuta una vez por lo que los efectos en el rendimiento serán nulos.
Sería necesario que dos hilos hallasen dos soluciones diferentes al
problema al mismo tiempo.

\subparagraph{\lstinline{open_set}}~

Segundo, el acceso al \lstinline{open_set} también 
debe estar controlado de forma que sólo un hilo
pueda interactuar con la estructura de datos compartida.
Esta interacción se presenta al menos en dos instancias por
cada iteración del bucle principal:
una primera vez para acceder al nodo a procesar
y otra para insertar los nuevos vecinos.
Si bien la obtención del nodo a procesar se realiza en $O(1)$
ya que el \lstinline{open_set} está ordenado y
siempre se accede al nodo en la cabeza de la lista,
la inserción de vecinos no corre la misma suerte.
Para que la lectura del nodo a procesar sea en $O(1)$
el \lstinline{open_set} se mantiene ordenado,
esto implica que la inserción ser haría en $O(n)$
\footnote{Esta implementación utiliza iteradores y
\lstinline{std::deque<T>} para hallar la posición de cada
nuevo elemento e insertarlo en el mismo barrido.}.

\begin{notebox}
    La complejidad de la sección crítica en la que se insertan
    elementos en el \lstinline{open_set}
    tiene como factor la longitud del \lstinline{open_set}. 
    Esto es, a mayor tamaño tenga el \lstinline{open_set},
    mayor tiempo será necesario para resolver la sección crítica.\\

    Nótese que a medida que avanza el programa,
    el tamaño del \lstinline{open_set} crece,
    incrementando la duración de la sección crítica y
    reduciendo la paralelización del algoritmo. 
\end{notebox}

\subsubsection{Batch Solver}
\index{Optimización A*!Multihilo!Batch Solver}

La siguiente estrategia es una evolución del FCFS Solver anterior,
utiliza el mismo principio (los hilos exploran nodos del \lstinline{open_set}
a medida que éste se va llenando),
pero en este caso se implanta una barrera de sincronización en cada iteración.
Esta barrera obliga a los hilos a esperar al resto de sus compañeros
antes de extraer otro nodo del \lstinline{open_set}.

La diferencia más notable entre este acercamiento y el anterior es que
las secciones críticas se ven reducidas porque las secciones paralelas
son menores.
Además, al sincronizar los hilos en cada iteración, ahora no existe ninguna
condición de carrera que pueda alterar el resultado, por lo que
para el mismo problema este algoritmo siempre retornará el mismo resultado
y utilizará la misma ruta para llegar a él.

Se utiliza un \lstinline{std::vector<State>} para almacenar los nodos
a explorar por cada hilo y un \lstinline{std::vector<std::vector<State>>}
para que cada hilo almacene los vecinos que ha encontrado.
Cada uno de estos vectores tiene una longitud igual al número de hilos
de forma que el hilo con ID $N$ tiene asignada la posición $N$ de cada
vector. Véase figura \ref{fig:RepresentacionBatch}.

\begin{figure}[h]
    \begin{center}
        \begin{tikzpicture}[node distance=2cm]
            \node (00) [process] {\lstinline{open_set}};
            \node (01) [process, below of=00] {Nodos a explorar};
            \node (02) [process, below of=01] {Procesa nodo};
            \node (03) [process, below of=02] {Vecinos a insertar};

            \draw [arrow] (00) -- (01);
            
            \draw [arrow] (01.south) -- ([xshift=-15mm]00.south |- 02.north);
            \draw [arrow] (01.south) -- ([xshift=-10mm]00.south |- 02.north);
            \draw [arrow] (01.south) -- ([xshift=-5mm]00.south |- 02.north);
            \draw [arrow] (01.south) -- (00.south |- 02.north);
            \draw [arrow] (01.south) -- ([xshift=15mm]00.south |- 02.north);
            \draw [arrow] (01.south) -- ([xshift=10mm]00.south |- 02.north);
            \draw [arrow] (01.south) -- ([xshift=5mm]00.south |- 02.north);

            \draw [arrow] (02.south) -- (03);
            \draw [arrow] (02.south)+(5mm,0) -- (03);
            \draw [arrow] (02.south)+(-5mm,0) -- (03);
            \draw [arrow] (02.south)+(10mm,0) -- (03);
            \draw [arrow] (02.south)+(-10mm,0) -- (03);
            \draw [arrow] (02.south)+(15mm,0) -- (03);
            \draw [arrow] (02.south)+(-15mm,0) -- (03);

            \draw [arrow] (03) to [bend left=3cm] node [anchor=east] {Inserta vecinos} (00);
        \end{tikzpicture}
    \end{center}
    \caption{Representación de la estrategia Batch}
    \label{fig:RepresentacionBatch}
\end{figure}

\begin{keynotebox}
    La estrategia Batch Solver
    explora el máximo número posible de nodos de forma simultánea,
    haciendo que los hilos esperen al resto cuando finalizan de
    explorar su nodo.

    El máximo número de nodos está limitado por el mínimo entre el
    número de nodos del \lstinline{open_set} y el número de hilos.
\end{keynotebox}

\paragraph{Secciones críticas}~

A diferencia de la estrategia FCFS,
no es posible que dos hilos accedan al mismo recurso
de forma simultánea.
Las únicas estructuras de datos compartidas
(los dos \lstinline{std::vector})
ofrecen a los hilos un índice privado al que acceder.
Las secciones críticas de la estrategia FCFS
ahora son ejecutadas por un hilo:
una al registrar los nodos a explorar y
otra al retirar los vecinos e insertarlos en el \lstinline{open_set}.

\subsubsection{Recursive Solver}
\index{Optimización A*!Multihilo!Recursive Solver}

La estrategia propuesta en \cite{Zag17} se basa en la ejecución
simultánea de varias instancias del algoritmo A* en el mismo problema.
\begin{enumerate}[start=0, itemsep=0.25px]
    \item Calcular vecinos del estado inicial.
    \item Asignar un hilo a cada vecino.
    \item Para cada vecino, resolver el problema como si fuese el estado inicial.
    \item Recoger resultados obtenidos.
    \item Obtener resultado con menor coste.
    \item Retornar.
\end{enumerate}

Al igual que la solución por batches,
no existe ninguna condición de carrera que permita
al algoritmo retornar resultados diferentes
en varias ejecuciones.
Originalmente cada hilo utiliza sus propias estructuras
de datos, por lo que no existen secciones críticas.
No obstante, sería posible hacer una versión en la que
los distintos hilos compartiesen las estructuras de costes
y el \lstinline{open_set}.
Implementar el algoritmo de esta forma añadiría las
tediosas secciones críticas que podrían ser más
dañinas que beneficiosas.

Este diseño puede ser de gran interés para otros problemas
distintos al JSP donde existan varios estados iniciales,
ya que sería posible calcular una solución del A*
para cada uno de ellos.
El algoritmo permitiría conocer el mejor estado inicial
así como la ruta a seguir para llegar al estado objetivo.

Uno de los posibles problemas que puede presentar esta
estrategia consiste en la posibilidad de que dos hilos
terminen calculando caminos muy similares.
Esto implica que uno de los hilos ha malgastado un tiempo
que podría haber sido invertido en rutas diferentes.
Para resolver este problema, sería necesario que
los hilos compartiesen alguna estructura de datos
para que sean conscientes de lo que está calculando cada uno.

\begin{keynotebox}
    El Recursive Solver es equivalente a ejecutar el algoritmo A*
    $N$ veces de de forma individual siendo $N$ el número
    de vecinos del nodo inicial.
\end{keynotebox}

\pagebreak

\subsubsection{Hash Distributed A* (HDA*) Solver}
\index{Optimización A*!Multihilo!Hash Distributed A* (HDA*) Solver}

El algoritmo propuesto en \cite{KFB09}
utiliza tantos \lstinline{open_set} como hilos
y una función hash para asignar cada nodo a uno de los
\lstinline{open_set}.
Cada hilo es `propietario' de uno de los \lstinline{open_set}
y por consecuente, de los nodos que estén contenidos
dentro del mismo.
Cada hilo está encargado de explorar los nodos de su
\lstinline{open_set} y de añadir sus vecinos
al \lstinline{open_set} correspondiente.

El rendimiento de este acercamiento depende en gran medida de la
función hash que se utilice para distribuir a los diferentes nodos.
Una función hash que no sea uniforme
\footnote{Una función hash es uniforme si los valores que retorna
tienen la misma probabilidad de ser retornados.}
distribuirá los nodos de forma poco equitativa
sobrecargando algunos hilos.
Por otro lado, al utilizar varios \lstinline{open_set},
el tiempo de inserción es menor porque tienen un menor tamaño.

\begin{figure}[h]
    \begin{center}
        \begin{tikzpicture}[node distance=4cm]
            \node (00) [stack] {\lstinline{open_set_0}};
            \node (01) [stack, right of=00] {\lstinline{open_set_1}};
            \node (02) [stack, right of=01] {\lstinline{open_set_2}};
            \node (03) [stack, right of=02] {\lstinline{open_set_3}};

            \node (04) [dot, below of=01, yshift=-2cm] {\lstinline{current_state}};

            \node (06) [process, below of=04] {\lstinline{Calculate neighbors}};

            \node (05) [dot, left of=06, yshift=2cm] {\lstinline{n_0}};
            \node (07) [dot, right of=06, yshift=2cm] {\lstinline{n_1}};
            \node (08) [dot, right of=06, xshift=4cm] {\lstinline{n_2}};

            \draw [arrow] (01.south) to node [anchor=west] {\lstinline{pop()}} (04);

            \draw [arrow] (04.south) to node [anchor=west] {\lstinline{process()}} (06);

            \draw [arrow] (06.west) to [bend left] node [anchor=north] {\lstinline{neighbor_0}} (05);
            \draw [arrow] (06.east) to [bend right] node [anchor=west] {\lstinline{neighbor_1}} (07);
            \draw [arrow] (06.east) to node [anchor=north] {\lstinline{neighbor_2}} (08);

            \draw [arrow] (05.north) to node [anchor=east] {\lstinline{insert()}} (00);
            \draw [arrow] (07.north) to node [anchor=east] {\lstinline{insert()}} (02);
            \draw [arrow] (08.north) to node [anchor=east] {\lstinline{insert()}} (03);
       \end{tikzpicture}
    \end{center}
    \caption{Representación de la estrategia HDA*}
    \label{fig:RepresentacionHDA}
\end{figure}

\begin{keynotebox}
    El Hash Distributed A* Solver es la única estrategia que utiliza
    un \lstinline{open_set} para cada hilo, reduciendo el tamaño de cada uno
    y aliviando el principal cuello de botella del algoritmo.
\end{keynotebox}

\section{FPGA}

Como se indicó en el resumen, una FPGA es un dispositivo capaz de emular
el comportamiento de un circuito integrado diseñado para resolver un problema
en particular (ASIC).
El principal beneficio de una FPGA es que es reprogramable
mientras que un circuito impreso no se puede modificar una vez producido.

El funcionamiento de una FPGA no se debe confundir con el de un procesador convencional.
Las CPUs comúnmente encontradas en ordenadores utilizan la arquitectura de Von Neumann
(Véase Figura \ref{fig:VonNeumann}) para realizar calculos.
Por otro lado, las FPGAs no utilizan esta arquitectura.
La principal diferencia se encuentra en la carga de instrucciones:
Una CPU tiene las instrucciones almacenadas en la memoria RAM
y se van cargando en la caché para poder ser leídas por la ALU
a medida se van necesitando.
Una FPGA no tiene las instrucciones almacenadas en ningún sitio,
las `instrucciones' están formadas principalmente por  puertas lógicas, registros y
\italic{Look-up Tables (LUTs)} que están `impresas' en el circuito
\footnote{
    A lo largo del documento, se hablará de la FPGA como si fuese un circuito impreso
    reprogramable.
    En realidad el dispositivo no tiene impresa ninguna puerta lógica,
    pero esta forma de verlo facilita mucho el entendimiento del hardware.
}.
Por la FPGA sólo `viajan' datos, nunca instrucciones.

\begin{figure}[h]
    \begin{subfigure}{.5\textwidth}
        \begin{center}
            \begin{tikzpicture}[node distance=2cm]
                \node (00) [process] {Memoria};
                \node (01) [process, above of=00] {Caché};
                \node (02) [process, above of=01] {Control};
                \node (03) [process, right of=02, xshift=2cm] {Registros};
                \node (04) [process, above of=03] {ALU};

                \draw [darrow] (00) -- (01);
                \draw [darrow] (01) -- node [anchor=east] {Instrucciones} (02);
                \draw [darrow] (01.east) to [bend right] node [anchor=north west] {Datos} (03.south);
                \draw [darrow] (03) -- node [anchor=west] {Datos} (04);
                \draw [darrow] (02.north) to [bend left] node [anchor=east] {Instrucciones} (04.west);
            \end{tikzpicture}
        \end{center}
        \subcaption{Arquitectura Von Neumann}
        \label{fig:VonNeumann}
    \end{subfigure}
    \begin{subfigure}{.5\textwidth}
        \begin{center}
            \begin{tikzpicture}[node distance=2cm]
                \node (00) [process] {Memoria};
                \node (01) [process, above of=00] {+};
                \node (02) [process, left of=01, xshift=-2cm] {+};
                \node (03) [process, above of=01] {+};

                \draw [arrow] (00) -- (01);
                \draw [arrow] (00.west) to [bend left] (02);
                \draw [arrow] (01) -- (03);
                \draw [arrow] (02) to [bend left] (03);
                \draw [arrow] (03.east) to [bend left] (00.east);
            \end{tikzpicture}
        \end{center}
        \subcaption{Arquitectura FPGA}
        \label{fig:FPGA}
    \end{subfigure}
\end{figure}

Entonces, los lenguajes en los que se suelen programar las FPGAs (VHDL, Verilog
\footnote{De ahora en adelante, se mencionará sólo VHDL,
nótese que VHDL y Verilog son lenguajes que sirven para lo mismo,
son intercambiables.})
permiten el uso de puertas lógicas, operaciones matemáticas
y movimiento de datos entre registros.
Este acercamiento es de muy bajo nivel, no admite programación orientada a objetos
ni facilita la abstracción.
Un programa escrito en estos lenguajes genera un \italic{bitstream}
que es la información escrita posteriormente en la FPGA.
Finalmente, las funciones del \italic{bitstream} que están escritas en
la FPGA pueden ser llamadas desde C/C++.

Alternativamente, se puede escribir código en C/C++ y utilizar una herramienta denominada
\italic{High Level Synthesizer (HLS)} (Sintetizador de Alto Nivel) que
transpila código C/C++ a VHDL.
Una vez generado el código VHDL se puede proceder por los cauces
correspondientes como si se hubiese escrito el código a mano en VHDL.

Como es de esperar, una solución escrita directamente en VHDL
tiene la oportunidad de estar mucho más optimizada que una solución transpilada utilizando HLS.
No obstante, en la mayoría de casos el código generado por HLS
suele ser lo suficientemente adecuado para cumplir las necesidades del programa.
En algunos casos de la literatura de este proyecto se ha utilizado
VHDL (\cite{ZJW20}) y en otros se ha optado por C/C++ y HLS (\cite{NSG17}).

Las operaciones en una FPGA siguen el mismo esquema: Un dato en un registro
se usa como operando en una operación y el resultado se almacena en otro registro.
El valor resultante puede ser leído como salida o puede utilizarse como
factor de otra operación.
Al conjunto de operaciones se le denomina \italic{pipeline},
la duración del mismo se mide en ciclos (e.g. número de puertas lógicas)
y la frecuencia con la que se pueden introducir nuevos datos de entrada
se denomina intervalo de iniciación.
Como los valores intermedios se almacenan en registros
es posible ejecutar la misma operación para varios datos
de forma casi paralela,
no es necesario que el dato de entrada permanezca en la entrada hasta finalizar
la operación.

\begin{figure}[h]
    \begin{center}
        \begin{tikzpicture}[node distance=1.5cm]
            \node (00) [process, fill=red!60] {+ (1)};
            \node (01) [process, below of=00, right of=00, xshift=2cm, fill=red!60] {+ (2)};
            \node (11) [process, below of=01, fill=yellow!60] {+ (1)};
            \node (02) [process, below of=01, right of=01, xshift=2cm, fill=red!60] {+ (3)};
            \node (12) [process, below of=02, fill=yellow!60] {+ (2)};
            \node (22) [process, below of=12, right of=12, xshift=2cm, fill=yellow!60] {+ (3)};
        \end{tikzpicture}
    \end{center}
    \caption{Dos operaciones ejecutadas en el mismo \italic{pipeline}.}
    \label{fig:Pipeline}
\end{figure}

La figura \ref{fig:Pipeline} muestra una simulación de un \italic{pipeline}
que realiza tres sumas a los datos de entrada.
La duración es de tres ciclos, pero es posible ejecutar dos veces la operación
utilizando tan sólo cuatro ciclos porque el intervalo es sólo de uno.
Adicionalmente, es posible replicar la impresión de las puertas lógicas
en distintas áreas de la FPGA, paralelizando el cálculo e incrementando la productividad.

Desde un punto de vista de bajo nivel, el principal desafío de programar una FPGA
se encuentra en minimizar el intervalo.
HLS siempre retornará la implementación con el mínimo intervalo posible a menos que se le indique lo contrario.
No obstante, HLS no modificará el código ni la secuencia de operaciones.

El hecho de que HLS no modifique el código ni la secuencia de operaciones es de vital importancia
para el desarrollo.
Esto implica que el programa se debe de escribir de forma que la implementación
resultante de HLS minimice el intervalo.

\begin{examplebox}
    El siguiente algoritmo en C:
    \begin{lstlisting}[language=C]
for (unsigned int i = 1 ; i < N - 1 ; i++)
{
    out[i] = in[i-1] + in[i] + in[i+1];
}
    \end{lstlisting}
    Sería un error transpilar este código en HLS
    porque en lugar de leer un valor y ejecutar una operación
    se estan leyendo tres valores y ejecutando una operación.
    Esto resultaría en un intervalo de tres en lugar de uno,
    dividiendo en tres la productividad del algoritmo en FPGA.

    En su lugar:
    \begin{lstlisting}[language=C]
int pprevious = in[0];
int previous = in[1];
for (unsigned int i = 1 ; i < N - 1 ; i++)
{
    const int current = in[i + 1];
    out[i] = pprevious + previous + current;
    pprevious = previous;
    previous = current;
}
    \end{lstlisting}
    Esta implementación sólo lee un valor en cada iteración
    y sustituye los que ya tiene en los registros convenientes.
    Al transpilar esta solución, se obtendría un algoritmo
    con un intervalo de un ciclo.
\end{examplebox}

Como se puede ver, una FPGA puede ser de gran utilidad para
implementar algunas funciones de un programa que posteriormente
sean llamadas desde un programa principal.
De esta forma, es posible centrar la atención de los desarrolladores
en optimizar las funciones utilizadas en la FPGA para reducir sus
intervalos.
Tambień es posible transpilar un programa completo a VHDL
para que sea ejecutado en una FPGA,
que sea más rentable una opción o la otra
es una cuestión dependiente en gran medida
del programa a implementar y del uso que se tenga pensado darle.
Es importante tener en cuenta que generalmente una FPGA cuenta con una
cantidad limitada de memoria, y que si bien existen FPGAs con mayor capacidad,
éstas suelen tener un coste notablemente más elevado.

\subsection{Síntesis}

Se ha llevado a cabo una síntesis de parte del código C++
a VHDL con el objetivo de observar principalmente los
beneficios de utilizar este hardware.
Adicionalmente este procedimiento también ha resultado
de utilidad para reconocer que a pesar de la existencia
de herramientas como HLS,
la migración de código existente en C++ al entorno de
la FPGA no es un procedimiento sin inconvenientes. 

La herramienta HLS nos permite seleccionar una única función
a acelerar en la FPGA.
Además, esta función no puede estar compuesta por
estructuras de datos (ni punteros a ellas)
que contengan punteros,
limitando nuestro abanico de datos de entrada a
prácticamente tipos de datos primitivos.
Si se introduce código C++ (como en el caso de esta
investigación), debe ser de la versión C++11 o inferior
ya que muchas características de versiones
posteriores no están soportadas.
Finalmente, la función a acelerar no puede ser un método
de una clase, descalificando la fácil migración
de cualquier programa que se base en programación orientada
a objetos.

Lógicamente estas restricciones dificultan la síntesis
de una función completa encargada de ejecutar el algoritmo A*
\footnote{Además, debido a la poca capacidad de memoria RAM
de la FPGA, una implementación de esta función sería capaz
de procesar problemas de tamaño 5x5x10 aproximadamente
como máximo.}.
Alternativamente, se puede sintetizar una función utilizada
durante la ejecución del algoritmo de forma que sólo esa función
esté acelerada en la FPGA.
De las posibles opciones, una mayoría de ellas quedan descartadas
por no tener el coste computacional suficiente,
mientras que otras quedan decartadas por cachearse
tras ser procesadas por primera vez (i.e. funciones hash).
Por último, queda la posibilidad de acelerar la función encargada
con insertar elementos en el \lstinline{open_set},
el principal cuello de botella del programa.

\section{Conjuntos de datos}
\index{Conjuntos de datos}

Los diferentes conjuntos de datos utilizados para medir el rendimiento
de las distintas implementaciones han sido obtenidos de
\href{http://jobshop.jjvh.nl/}{(HTTP) Jobshop Instances}
o diseñados a mano.

Para desarrollar el programa se han utilizado conjuntos de datos
personalizados hechos a mano para facilitar la creación
de pruebas de software que comprueben el correcto funcionamiento
del algoritmo.

Para ejecutar las pruebas se han utilizado porciones de conjuntos
de datos obtenidos de \href{http://jobshop.jjvh.nl/}{(HTTP) Jobshop Instances}.
En particular se ha utilizado el $40\percentsign$, $50\percentsign$, $60\percentsign$ del conjunto
`abz5' (4x4x10, 5x5x10, 6x6x10), o el $100\percentsign$ de `ft06' (6x6x6).
El algoritmo utilizado para importar y cortar
los conjuntos de datos se puede encontar en el Anexo \ref{sec:ReadAndCut}.

\begin{notebox}
    \index{Tamaño del problema}
    Un conjunto de datos tiene un tamaño de $A$x$B$x$C$ cuando
    está compuesto por $A$ trabajos, $B$ tareas en cada uno y $C$ trabajadores.
\end{notebox}

\pagebreak

\section{Equipos de Prueba}
\index{Equipos de Prueba}

\subsection{Arquitectura x86}
\index{Equipos de Prueba!Arquitectura x86}

Se han utilizado 3 equipos diferentes para tomar y contrastar las mediciones.

\begin{center}
    \begin{table}[h]
        \centering
        \begin{tabular}{ l | l l l }
            \hline
            ID & Tipo & OS & Versión \\
            \hline
            0 & Escritorio & Arch Linux & 6.9.6-arch1-1 \\
            1 & Servidor & Debian Linux 12 \italic{`Bookworm'} & 6.1.0-16-amd64 \\
            2 & Portátil & Debian Linux 12 \italic{`Bookworm'} & 6.1.0-16-amd64 \\
            \hline
        \end{tabular}
        \caption{Equipos de prueba, arquitectura x86: OS}
    \end{table}
\end{center}

\begin{center}
    \begin{table}[h]
        \centering
        \begin{tabular}{ l | l l l l }
            \hline
            ID & Familia & Modelo & Hilos & Reloj \\
            \hline
            0 & Intel & Core I7-9700F & 8c8t & 4.7GHz \\
            1 & Intel & Xeon-E5450 & 4c4t & 3GHz \\
            2 & AMD & Ryzen 7 5700U & 8c16t & 4.3GHz \\
            \hline
        \end{tabular}
        \caption{Equipos de prueba, arquitectura x86: CPU}
    \end{table}
\end{center}

\begin{center}
    \begin{table}[h]
        \centering
        \begin{tabular}{ l | l l r r}
            \hline
            ID & RAM & Formato & Tipo & Reloj \\
            \hline
            0 & 64GB & 4x16 & DDR4 & 3200MHz \\
            1 & 8GB & 2x4 & DDR3 & 2666MHz \\
            2 & 16GB & 2x8 & DDR4 & 3200MHz \\
            \hline
        \end{tabular}
        \caption{Equipos de prueba, arquitectura x86: RAM}
    \end{table}
\end{center}

\pagebreak

\section{Método de medición}

Todas las versiones imprimen por salida estándar datos que posteriormente son
procesados en formato CSV:

\begin{itemize}[itemsep=0.25px]
    \item Lenguaje
    \item Número de hilos
    \item Porcentaje del trabajo resuelto
    \item Trabajos
    \item Tareas
    \item Trabajadores
    \item Tiempo de ejecución
    \item Planificación
    \item \italic{Makespan}
\end{itemize}

La alta complejidad del JSP implica que un mínimo aumento en el tamaño del problema
puede implicar que el algoritmo no finalice su ejecución en un tiempo polinomial.
Por ello, en lugar de tomar una única medición al inicio y final de la ejecución
se ha optado por utilizar un objeto personalizado que toma mediciones en intervalos
predefinidos\footnote{Véase \ref{lst:Chronometer}}.
De esta forma, de una única ejecución se podría obtener:

\begin{itemize}[itemsep=0.25px]
    \item Tiempo de inicio.
    \item Tiempo necesario para resolver el $10\percentsign$ del problema.
    \item Tiempo necesario para resolver el $20\percentsign$ del problema.
    \item \dots
    \item Tiempo necesario para resolver el $90\percentsign$ del problema.
    \item Tiempo necesario para resolver el $100\percentsign$ del problema.
\end{itemize}

\section{Métricas}

A continuación se listan las diferentes métricas observadas a la hora
de estudiar y criticar las implementaciones del algoritmo:
\begin{itemize}[itemsep=0.25px]
    \item Tiempo de ejecución - Menor implica mejor.
    \item \italic{Speedup} - Mayor implica mejor.
    \item \italic{Makespan} - Menor implica mejor.
    \item Consumo de CPU \footnote{
        Dependiendo de otras métricas, el consumo de CPU se
        puede utilizar para `desempatar' algoritmos que
        aparentemente tengan los mismos resultados,
        en cuyo caso menor implica mejor.
    }.
\end{itemize}

\subsection{\italic{Speedup}}
\index{Speedup}

Sean $T_1$ y $T_0$ dos métricas del tiempo de ejecución
de dos algoritmos distintos ($A0$ y $A1$),
el \italic{speedup} del algoritmo $A0$ respecto al $A1$ ($S_{A0,A1}$) es:
$$
    S_{A0,A1} = T_1 / T_0
$$

\begin{examplebox}
    Si el algoritmo $A0$ tardó $5s$ en finalizar y
    $A1$ tardó $10s$, el \italic{speedup} ($S_{A0,A1}$):
    $$
        S_{A0,A1} = T_1 / T_0 = 10 / 5 = 2
    $$
    $A0$ es el doble de rápido que $A1$.
\end{examplebox}

Por lo tanto:
$$ S_{A0,A1} = 1 \rightarrow T_1 = T_0 $$ 
$$ S_{A0,A1} > 1 \rightarrow T_1 > T_0 $$ 
$$ S_{A0,A1} < 1 \rightarrow T_1 < T_0 $$

\begin{keynotebox}
    Un \italic{speedup} inferior a 1 implica una reducción en el rendimiento.\\
    Un \italic{speedup} superior a 1 implica un incremento en el rendimiento. 
\end{keynotebox}

\subsection{\italic{Makespan}}
\index{Makespan}

El \italic{makespan} es el tiempo necesario para completar
todos los trabajos de un conjunto de datos,
es el `resultado' que genera el algoritmo.
Lógicamente, el \italic{makespan} óptimo es el mínimo.
El algoritmo desarrollado en este proyecto
no tiene la certeza de obtener el resultado óptimo.
Por ello, si una implementación $A$ retorna
resultados con un \italic{makespan} que otra $B$,
$A$ es mejor que $B$ \footnote{
    Suponiendo que el resto de métricas entre $A$ y $B$
    son lo suficientemente similares.
}.

\begin{examplebox}
    Sea la siguiente planificación:
    \begin{itemize}[itemsep=0.25px]
        \item Planificación:
        \begin{enumerate}[itemsep=0.25px]
            \item (0, 3, 5)
            \item (0, 3, 3)
        \end{enumerate}
        \item Estado trabajadores: (2, 8, 3)
    \end{itemize}

    El \italic{makespan} es $max([2, 8, 3]) = 8$.
\end{examplebox}

\section{Resultados y Análisis}
\index{Resultados}

\subsection{Complejidad del problema}
\index{Resultados!Complejidad del problema}

\begin{notebox}
    Como se ha visto, el algoritmo A* es bastante modular,
    existen diversas partes intercambiables que resulta en un gran
    número de posibilidades a probar.
    Las ejecuciones realizadas a continuación se basan en probar
    distintas combinaciones que resultan de interés.
    Para simplificar la lectura de los resultados mostrados
    en las gráficas, a continuación se muestra un resumen de
    las variables utilizadas en las mismas:

    \begin{itemize}[itemsep=0.25px]
        \item Número de hilos: 1T, 4T, 8T\dots
        \item Solucionador: `FCFS Solver', `HDA* Solver', `Recursive Solver'\dots
        \item Heurísticos: `Fast', `Slow'\dots\footnote{La falta de una etiqueta para el heurístico implica el óptimo (también llamado slow)}
        \item Problema: 60\percentsign abz5.csv (6x6x10), 40\percentsign abz5.csv (4x4x10)\dots
    \end{itemize}

    Si todas las mediciones de la gráfica coinciden en una de las
    variables, ésta se anotará en el subtítulo de la gráfica.

    \begin{examplebox}
        \begin{itemize}[itemsep=0.25px]
            \item `4 FCFS Solver Fast': FCFS con 4 hilos y el heurístico rápido.
            \item `2 HDA* Solver': FCFS con 2 hilos y el heurístico lento (óptimo).
        \end{itemize}
    \end{examplebox}
\end{notebox}

\pagebreak

En la siguiente gráfica (figura \ref{fig:Runtime_One_Problem_Linear}),
se puede ver el tiempo de ejecución
necesario para completar el problema utilizando uno de los
algoritmos.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{Media/Ch2/Runtime_One_Problem_Linear.png}
    \caption{Tiempo de ejecución de un único problema.}
    \label{fig:Runtime_One_Problem_Linear}
\end{figure}

Como se puede ver, el diagrama es de poca utilidad debido a la
complejidad del problema.
Para poder observar con mejor los resultados,
se utiliza un eje vertical con una escala logarítmica
(figura \ref{fig:Runtime_One_Problem_Log}).

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{Media/Ch2/Runtime_One_Problem_Log.png}
    \caption{Tiempo de ejecución de un único problema (escala logarítmica).}
    \label{fig:Runtime_One_Problem_Log}
\end{figure}

Estas observaciones verifican que la complejidad del problema
a resolver es cuadrática, como era de esperar.

\begin{notebox}
    Este capítulo contiene diversas gráficas de las métricas obtenidas,
    obsérvese con detalle la escala utilizada en el eje de ordenadas de cada una
    ya que en algunos casos será logarítmica.
\end{notebox}

\subsection{Comparativa de heurísticos}
\index{Resultados!Heurísticos}

Como ya se discutió en la sección sobre optimización (\ref{ssec:Heuristicos}),
existen varias implementaciones de la función heurística que da al algoritmo
A* su particular comportamiento de ir `dirigido' hacia la solución.
En esta investigación se han implementado dos heurísticos:
uno de ellos busca una solución que se acerque a la óptima lo máximo posible
mientras que el otro busca la solución priorizando la velocidad del algoritmo.
A continuación se comparan los heurísticos utilizando la implementación paralela HDA*.

En primer lugar se observa que existe un limitado número de soluciones
propuestas, las más comunes siendo también las más bajas: 452 y 472.
Respecto al tiempo de ejecución, las pruebas que utilizan el heurístico rápido
reducen el tiempo de ejecución en varias magnitudes.

\begin{figure}[h]
    \begin{subfigure}{.5\textwidth}
        \begin{center}
            \includegraphics[width=\textwidth]{Media/Ch2/Makespan_8_Heuristics.png}
            \subcaption{\italic{Makespan} con 8 hilos.}
        \end{center}
    \end{subfigure}
    \begin{subfigure}{.5\textwidth}
        \begin{center}
            \includegraphics[width=\textwidth]{Media/Ch2/Runtime_8_Heuristics.png}
            \subcaption{Tiempo de ejecución con 8 hilos.}
        \end{center}
    \end{subfigure}
    \caption{Métricas de heurísticos con 8 hilos.}
    \label{fig:Heuristico8}
\end{figure}

\begin{figure}[h]
    \begin{subfigure}{.5\textwidth}
        \begin{center}
            \includegraphics[width=\textwidth]{Media/Ch2/Makespan_4_Heuristics.png}
            \subcaption{\italic{Makespan} con 4 hilos.}
        \end{center}
    \end{subfigure}
    \begin{subfigure}{.5\textwidth}
        \begin{center}
            \includegraphics[width=\textwidth]{Media/Ch2/Runtime_4_Heuristics.png}
            \subcaption{Tiempo de ejecución con 4 hilos.}
        \end{center}
    \end{subfigure}
    \caption{Métricas de heurísticos con 4 hilos.}
    \label{fig:Heuristico4}
\end{figure}

\begin{figure}[h]
    \begin{subfigure}{.5\textwidth}
        \begin{center}
            \includegraphics[width=\textwidth]{Media/Ch2/Makespan_1_Heuristics.png}
            \subcaption{\italic{Makespan} con 1 hilo.}
        \end{center}
    \end{subfigure}
    \begin{subfigure}{.5\textwidth}
        \begin{center}
            \includegraphics[width=\textwidth]{Media/Ch2/Runtime_1_Heuristics.png}
            \subcaption{Tiempo de ejecución con 1 hilo.}
        \end{center}
    \end{subfigure}
    \caption{Métricas de heurísticos con 1 hilo.}
    \label{fig:Heuristico1}
\end{figure}

Analizandolas por separado, las ejecuciones que utilizan el heurístico lento
retornaron siempre 452 o 472, los dos mejores resultados y se vieron
beneficiadas por el uso de varios hilos.
Por otro lado, las ejecuciones que utilizan el heurístico rápido
sólo retornaron 452 o 472 en algunas instancias y no se vieron
beneficiadas por el uso de varios hilos
(Véase figuras \ref{fig:Heuristico8}, \ref{fig:Heuristico4} y \ref{fig:Heuristico1}).

Sería razonable suponer que el heurístico rápido
sí se vería beneficiado por el paralelismo si el tamaño del
problema fuese lo suficientemente grande.
Para comprobar esta hipótesis, se ha creado un conjunto
con un tamaño mucho mayor (70x10x10) y se ha obtenido el \italic{speedup}.

Además, se puede observar una clara tendencia en los resultados que utilizan
el heurístico rápido. A menor número de hilos, mejor \italic{makespan} retornan.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{Media/Ch2/Speedup_Large_Problem.png}
    \caption{\italic{Speedup} en un problema de gran tamaño.}
    \label{fig:Speedup_Large_Problem}
\end{figure}

La gráfica (\ref{fig:Speedup_Large_Problem}) muestra que incluso en un problema de mayor tamaño
la versión monohilo es más rápida que las multihilo.
Esta investigación no ha podido encontrar un conjunto de datos
en el que utilizando el heurístico rápido valga la pena el paralelismo.
No obstante, se ha observado que a medida que el tamaño
del problema incrementa, el \italic{speedup} también se ve incrementado
por lo que si se supone que la tendencia del \italic{speedup}
se mantiene, sería razonable suponer que existe un tamaño de
problema donde sí vale la pena utilizar varios hilos y 
el heurístico rápido.

Se deja también constancia de que las pruebas ejecutadas indican que
el error cometido por el heurístico rápido incrementa proporcionalmente
con el tamaño del problema.
En las pruebas que utilizaron conjuntos de datos de 6x6x10,
el error se encontraba entre 20 y 50, mientras que en
conjuntos de datos de 70x10x10, el error se podría encontrar
en los miles.
Por ello, el heurístico rápido se podría considerar únicamente para
resolver problemas de menor tamaño e incluso en esos casos
se debería tener en cuenta su falta de precisión.

\subsubsection{Comparativa con Random Solver}

El heurístico rápido obtiene resultados cuya calidad es razonable
únicamente cuando se tiene en cuenta la velocidad con la que
los obtiene.
Se ha implementado un algoritmo (no A*) que resuelve
el problema del JSP de forma aleatoria (Anexo \ref{sec:RandomSolver}),
esto es, selecciona una tarea cualquiera y la introduce en el plan.
Como el nombre del \italic{solver} indica, la planificación
que retorna este algoritmo es aleatoria.
Utilizamos estos resultados para criticar el \italic{makespan}
del heurístico rápido.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{Media/Ch2/Makespan_Random_Solver.png}
    \caption{\italic{Makespan} de diferentes heurísticos}
    \label{fig:MakespanRandomSolver}
\end{figure}

La figura \ref{fig:MakespanRandomSolver} muestra el \italic{makespan}
del heurístico óptimo (el lento), el rápido y el obtenido
por el Random Solver.
Adicionalmente, se muestran también los \italic{makespan}
máximo y mínimo obtenidos por cada uno de ellos.

Como se puede ver en el diagrama, el heurístico rápido obtiene mejores
resultados que el Random Solver y más importantemente tiene un
margen de error mucho menor.
Entonces, aunque los resultados del heurístico rápido no
sean óptimos, son mejores que crear una planificación aleatoria.

\subsection{Cuellos de botella en secciones críticas}
\index{Resultados!Cuellos de botella}

Los algoritmos que utilizan estructuras de datos compartidas
para almacenar los nodos y sus costes se ven gravemente
afectadas cuando el tamaño de estas estructuras incrementa.
Como esta información es compartida por todos los hilos,
es necesario acceder a ella de forma serializada,
reduciendo notablemente el \italic{speedup}.

En algunos casos extremos es posible incluso
que versiones monohilo del mismo algoritmo
tengan mejor rendimiento que versiones paralelas.
Nótese que el \italic{speedup} del algoritmo FCFS
cuando se utilizan varios hilos (respecto a un hilo solo)
es inferior a $1$.
(Véase figura \ref{fig:SpeedupFCFS}).

\begin{figure}[h]
    \begin{subfigure}{.5\textwidth}
        \begin{center}
            \includegraphics[width=\textwidth]{Media/Ch2/Runtime_FCFS_Log.png}
            \subcaption{Tiempo de ejecución de FCFS.}
        \end{center}
    \end{subfigure}
    \begin{subfigure}{.5\textwidth}
        \begin{center}
            \includegraphics[width=\textwidth]{Media/Ch2/Speedup_FCFS.png}
            \subcaption{\italic{Speedup} de FCFS.}
            \label{fig:SpeedupFCFS}
        \end{center}
    \end{subfigure}
    \caption{Métricas de paralelismo en FCFS.}
    \label{fig:ParalelismoFCFS}
\end{figure}

Por otro lado, algoritmos como el HDA*
que utilizan una estructura de datos privada para cada hilo
no ven sus tareas serializadas,
incrementando notablemente el \italic{speedup}
(Véase figura \ref{fig:ParalelismoHDA}).

\begin{figure}[h]
    \begin{center}
        \includegraphics[width=\textwidth]{Media/Ch2/Speedup_One_Problem.png}
    \end{center}
    \caption{\italic{Speedup} de HDA*.}
    \label{fig:ParalelismoHDA}
\end{figure}

Nótese que al inicio del problema (aproximadamente hasta completar el $20\percentsign$)
la versión monohilo de los algoritmos es más rápida que cualquier multihilo.
Esto se debe a que para tamaños de problema muy pequeños
el coste de crear $N$ hilos es superior al de resolver el problema
utilizando uno sólo.

Si se observa el \italic{speedup} al final del problema,
la versión con cuatro hilos tiene un \italic{speedup}
de $3.5$ mientras que la de ocho tiene $5.5$.
Esto implica que al utilizar cuatro hilos,
el algoritmo ha sido capaz de aprovecharlos casi al máximo
ya que el tiempo de ejecución casi se reduce en 4
veces.
Mientras tanto, al utilizar 8 hilos el algoritmo
no ha sido capaz de rentabilizarlos en la misma proporción.
Este déficit podría deberse a que el tamaño del problema
es demasiado pequeño para aprovechar la cantidad de hilos
o podría deberse al propio diseño del algoritmo.

\subsection{Comparativa de algoritmos}
\index{Resultados!Comparativa de algoritmos}

Como es de esperar, el rendimiento monohilo de todas
las implementaciones es el mismo.
Todas las implementaciones están diseñadas de forma
que al ser ejecutadas con un sólo hilo
el algoritmo sea el A* básico.

\begin{figure}[h]
    \begin{center}
        \includegraphics[width=\textwidth]{Media/Ch2/Runtime_All_Algorithms_1.png}
    \end{center}
    \caption{Tiempo de ejecución de todos los algoritmos (1 hilo).}
    \label{fig:MetricasSinglethread}
\end{figure}

\begin{figure}[h]
    \begin{subfigure}{.5\textwidth}
        \begin{center}
            \includegraphics[width=\textwidth]{Media/Ch2/Runtime_All_Algorithms_4.png}
            \subcaption{Tiempo de ejecución de todos los algoritmos (4 hilos).}
        \end{center}
    \end{subfigure}
    \begin{subfigure}{.5\textwidth}
        \begin{center}
            \includegraphics[width=\textwidth]{Media/Ch2/Speedup_All_Algorithms_4.png}
            \subcaption{\italic{Speedup} de todos los algoritmos (4 hilos).}
        \end{center}
    \end{subfigure}
    \caption{Métricas con 4 hilos.}
    \label{fig:Metricas4Thread}
\end{figure}

Al utilizar cuatro hilos (figura \ref{fig:Metricas4Thread}), se puede comenzar a ver una diferencia clara
en el rendimiento del algoritmo HDA*, que obtiene un \italic{speedup}
de casi 4.

\begin{figure}[h]
    \begin{subfigure}{.5\textwidth}
        \begin{center}
            \includegraphics[width=\textwidth]{Media/Ch2/Runtime_All_Algorithms_8.png}
            \subcaption{Tiempo de ejecución de todos los algoritmos (8 hilos).}
        \end{center}
    \end{subfigure}
    \begin{subfigure}{.5\textwidth}
        \begin{center}
            \includegraphics[width=\textwidth]{Media/Ch2/Speedup_All_Algorithms_8.png}
            \subcaption{\italic{Speedup} de todos los algoritmos (8 hilos).}
        \end{center}
    \end{subfigure}
    \caption{Métricas con 8 hilos.}
    \label{fig:Metricas8Thread}
\end{figure}

Al utilizar ocho hilos (figura \ref{fig:Metricas8Thread}), el algoritmo HDA* incremente aún más su diferencia
en el tiempo de ejecución con respecto al resto de algoritmos,
aunque esta vez el \italic{speedup} fluctua más.
De cualquier forma, parece ser capaz de alcanzar casi 8.

La principal conclusión de estas observaciones es que
(al menos en los conjuntos de datos observados)
el paralelismo es sólo rentable si se implementa el HDA*.
En el resto de casos, el paralelismo sólo sirve para
gastar núcleos y ciclos de CPU a cambio de nada.

\begin{notebox}
    En la inmensa mayoría de observaciones realizadas,
    el algoritmo Batch Solver
    ha sido capaz de resolver el $30\percentsign$ del problema
    en menos tiempo que cualquier otro algoritmo.
    Esta reducción de tiempo se debe a que este algoritmo ejecuta el A*
    tantas veces como hilos haya disponibles de forma simultánea,
    facilitando la obtención de planificaciones profundas más rápido. 
    En otras palabras, el algoritmo es más veloz al iniciar el problema
    pero es más lento al final.
\end{notebox}

\subsection{Comparativa con Dijkstra}
\index{Resultados!Comparativa con Dijkstra}
\label{sec:ComparativaDijkstra}

Como se indicó brevemente al inicio de este documento (Subsección \ref{ssec:AlgoritmoA*}),
el algoritmo A* es una evolución del de Dijkstra
donde la principal diferencia es la inclusión de una función
heurística utilizada para seleccionar el siguiente nodo a explorar.
Entonces, se podría decir que el algoritmo de Dijkstra es una
versión particular del algoritmo A* donde la función heurística
retorna siempre 0.

La principal conclusión obtenida de las siguientes observaciones 
(Figura \ref{fig:Speedup_Dijkstra}) es que el \italic{speedup}
del algoritmo A* frente a Dijkstra
es tan grande que incluso resulta complicado realizar pruebas.
Esto se debe a que los conjuntos de datos que se pueden
resolver utilizando Dijkstra en un tiempo razonable son resueltos
en microsegundos por A* y los que son resueltos en un tiempo
razonable por A* requerirían meses de ejecución para resolverlos
utilizando Dijkstra
\footnote{
    Es recomendable evitar extraer conclusiones de observaciones cuyo tiempo de ejecución es muy reducido.
    Existe un gran número de variables (cambios de contexto, fallos de caché, interrupciones del OS)
    que pueden afectar al tiempo de ejecución de un algoritmo,
    desvirtuando la medición.
}.

\begin{figure}[h]
    \centering
    %\includesvg{./Media/Ch2/Speedup_Dijkstra.svg}
    \includegraphics[width=\linewidth]{Media/Ch2/Speedup_Dijkstra.png}
    \caption{\italic{Speedup} de A* frente a Dijkstra}
    \label{fig:Speedup_Dijkstra}
\end{figure}

Como era de esperar, el rendimiento de las implementaciones A*
es notablemente superior al de Dijkstra en lo que corresponde
a tiempo de ejecución.
El gráfico anterior muestra que como poco el algoritmo A*
tiene un \italic{speedup} de 8000 frente a Dijkstra
en el conjunto de datos estudiado.

No obstante, las ejecuciones de Dijkstra han sido capaces
de obtener un \italic{makespan} mejor que las de A*.
El algoritmo de Dijkstra explorará todos los
nodos posibles hasta obtener una solución óptima
mientras que el A* simplemente explorará nodos
hasta que se cumpla la condición de salida
\footnote{En este caso que todas las tareas estén planificadas}.

El algoritmo A* es completo, retornará una solución al problema
siempre y cuando exista al menos una.
Por otro lado, el algoritmo A* no tiene por qué retornar la
solución óptima al problema.
Esta característica depende de la función heurística
encargada de calcular el coste H.
Si la función heurística subestima el coste H real
(es cota inferior del coste H real)
entonces A* retornará la solución óptima.
En otro caso, A* retornará una solución que puede
ser la óptima.

De cualquier forma, las funciones heurísticas no son
categorizables en una u otra clase,
más bien se trata de un espectro.
Las funciones heurísticas que subestimen
el coste H real se denominan `optimistas'
mientras que las que lo igualan o sobreestiman
se denominan `pesimistas'.
\begin{keynotebox}
Las funciones optimistas retornarán los resultados óptimos
pero requerirán un mayor tiempo de ejecución ya que
se verán obligadas a explorar un mayor número de nodos
mientras que las pesimistas no tienen por qué retornar un
resultado óptimo y tendrán una mayor velocidad porque
no explorarán tantas posibilidades.
\end{keynotebox}

Al extremo de las funciones optimistas
se encuentra el algoritmo de Dijkstra
cuyo heurístico retorna siempre 0
(no hay coste más bajo) y
al extremo de las funciones pesimistas se podría encontrar la siguiente
función (\ref{eq:HeuristicoPesimista})
donde $J$ es el número total de trabajos, $T$ el de tareas y $D_{i,j}$
la duración de la tarea $j$ del trabajo $i$.

\begin{figure}[h]
    $$
    cost_h = \sum_{j=0}^{J}{
        \sum_{t=0}^{T}{
            D_{j,t}
        }
    }
    $$
    \caption{Función heurística pesimista}
    \label{eq:HeuristicoPesimista}
\end{figure}

Una función que calcula el sumatorio de todas las duraciones
de las tareas restantes por planificar.
Este heurístico sería lo equivalente a planificar
que cada tarea se ejecute una a una de forma
que sólo un trabajador se encuentra activo mientras
el resto esperan (aunque puedan hacer tareas de forma paralela).

En algún punto intermedio entre estos dos extremos
se encontraría el heurístico óptimo utilizado
en la mayoría de las pruebas de esta investigación,
pero es difícil de saber si se acerca más
a los algoritmos optimistas o pesimistas.
La principal dificultad de implementar el algoritmo A*
es entonces decidir una función heurística
que sea lo suficientemente pesimista para retornar resultados óptimos
pero no tan pesimista que explore demasiadas alternativas.

\pagebreak

\subsection{Casos particulares}
\index{Resultados!Casos particulares}

Vistos los resultados anteriores
se podrían dar como obsoletas algunas de las versiones
paralelas por ofrecer muy pocas mejoras frente a otras
versiones monohilo.
No obstante, existen casos particulares del problema
donde estas versiones fácilmente descartables
podrían presentar una solución mucho más interesante.

Estos casos particulares generalmente involucran
la posibilidad de que la población de nodos sea
repartida entre los diferentes hilos de forma
que cada uno tenga una sección parcial o totalmente
independiente del resto.
A continuación se presentan algunos de estos casos.

\subsubsection{Varios estados iniciales}
\index{Resultados!Casos particulares!Varios estados iniciales}

Si el problema a resolver tiene varios estados iniciales
sería posible asignar cada estado a un hilo (o grupo de hilos)
de forma que cada uno busque una solución desde su estado inicial.

\subsubsection{Estados solución intermedios}
\index{Resultados!Casos particulares!Estados solución intermedios}

Si se conoce algún nodo intermedio de la solución
sería posible dividir el problema en dos,
de forma que un hilo resuelva una de las partes
\footnote{Si existiese más de un nodo intermedio conocido,
el problema se podría seguir subdividiendo entre más hilos.}.
Por ejemplo, si del problema se conocen el nodo inicial $A$,
el final $E$ y los intermedios $B$, $C$ y $D$,
la solución se podría obtener repartiendo el
trabajo entre 4 hilos diferentes:
\begin{enumerate}[start=0, itemsep=0.25px]
    \item Hilo 0: Resolver camino desde nodo $A$ hasta $B$.
    \item Hilo 1: Resolver camino desde nodo $B$ hasta $C$.
    \item Hilo 2: Resolver camino desde nodo $C$ hasta $D$.
    \item Hilo 3: Resolver camino desde nodo $D$ hasta $E$.
\end{enumerate}
